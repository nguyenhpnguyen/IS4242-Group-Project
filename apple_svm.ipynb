{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VuaIthL0yPtb"
      },
      "outputs": [],
      "source": [
        "import h5py\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score, roc_auc_score, roc_curve, precision_score, recall_score\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKQAdbqSx1ZG",
        "outputId": "92a95d15-7405-44b0-fa87-57a1cca8f54f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded HDF5 file with images of shape: (857, 128, 128, 3)\n"
          ]
        }
      ],
      "source": [
        "# Path to your HDF5 file\n",
        "hdf5_file_path = 'preprocessed_images_h5'\n",
        "\n",
        "# Open the HDF5 file\n",
        "with h5py.File(hdf5_file_path, 'r') as hf:\n",
        "    # Access the dataset containing images\n",
        "    images = hf['preprocessed_images'][:]\n",
        "\n",
        "# Now 'images' variable contains your array of images\n",
        "# You can use it as needed\n",
        "print(f\"Loaded HDF5 file with images of shape: {images.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hv3hqFFNyU7T",
        "outputId": "b0dd7642-46d1-44e2-a175-2937276a5d86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded HDF5 file with labels of shape: (857,)\n"
          ]
        }
      ],
      "source": [
        "# Path to your HDF5 file\n",
        "hdf5_file_path = 'labels_h5'\n",
        "\n",
        "# Open the HDF5 file\n",
        "with h5py.File(hdf5_file_path, 'r') as hf:\n",
        "    # Access the dataset containing images\n",
        "    labels = hf['labels'][:]\n",
        "\n",
        "# Now 'images' variable contains your array of images\n",
        "# You can use it as needed\n",
        "print(f\"Loaded HDF5 file with labels of shape: {labels.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "1dRcbSV_yZbW"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(685, 49152)\n",
            "(172, 49152)\n"
          ]
        }
      ],
      "source": [
        "X_train_flat = X_train.reshape(X_train.shape[0], X_train.shape[1]*X_train.shape[2]*X_train.shape[3])\n",
        "print(X_train_flat.shape)\n",
        "X_test_flat = X_test.reshape(X_test.shape[0], X_test.shape[1]*X_test.shape[2]*X_test.shape[3])\n",
        "print(X_test_flat.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjdQeUgZyfhZ",
        "outputId": "e292276d-ecf5-421e-9ac9-eec501f6c5fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['France grn' 'Fuji' 'USA Envy' 'USA Koru']\n"
          ]
        }
      ],
      "source": [
        "y_train_decode = [label.decode() for label in y_train]\n",
        "y_test_decode = [label.decode() for label in y_test]\n",
        "print(np.unique(y_train_decode))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "wQwxgu_8znz9",
        "outputId": "5c7e37a2-8dcf-46c2-c4d2-fc24aaf194d5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>49142</th>\n",
              "      <th>49143</th>\n",
              "      <th>49144</th>\n",
              "      <th>49145</th>\n",
              "      <th>49146</th>\n",
              "      <th>49147</th>\n",
              "      <th>49148</th>\n",
              "      <th>49149</th>\n",
              "      <th>49150</th>\n",
              "      <th>49151</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007843</td>\n",
              "      <td>0.078431</td>\n",
              "      <td>0.235294</td>\n",
              "      <td>0.011765</td>\n",
              "      <td>0.125490</td>\n",
              "      <td>0.356863</td>\n",
              "      <td>0.011765</td>\n",
              "      <td>...</td>\n",
              "      <td>0.305882</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.109804</td>\n",
              "      <td>0.305882</td>\n",
              "      <td>0.039216</td>\n",
              "      <td>0.070588</td>\n",
              "      <td>0.203922</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.050980</td>\n",
              "      <td>...</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.011765</td>\n",
              "      <td>0.011765</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.043137</td>\n",
              "      <td>0.047059</td>\n",
              "      <td>0.227451</td>\n",
              "      <td>0.047059</td>\n",
              "      <td>...</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.054902</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.392157</td>\n",
              "      <td>0.011765</td>\n",
              "      <td>0.035294</td>\n",
              "      <td>0.101961</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>680</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>681</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>682</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>683</th>\n",
              "      <td>0.027451</td>\n",
              "      <td>0.039216</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.160784</td>\n",
              "      <td>0.239216</td>\n",
              "      <td>0.352941</td>\n",
              "      <td>0.145098</td>\n",
              "      <td>0.223529</td>\n",
              "      <td>0.337255</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.349020</td>\n",
              "      <td>0.321569</td>\n",
              "      <td>0.321569</td>\n",
              "      <td>0.352941</td>\n",
              "      <td>0.321569</td>\n",
              "      <td>0.325490</td>\n",
              "      <td>0.356863</td>\n",
              "      <td>0.054902</td>\n",
              "      <td>0.054902</td>\n",
              "      <td>0.058824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>684</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>685 rows × 49152 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0         1         2         3         4         5         6      \\\n",
              "0    0.000000  0.000000  0.000000  0.007843  0.078431  0.235294  0.011765   \n",
              "1    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "2    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "3    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "4    0.000000  0.000000  0.000000  0.011765  0.011765  0.058824  0.043137   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "680  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "681  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "682  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "683  0.027451  0.039216  0.058824  0.160784  0.239216  0.352941  0.145098   \n",
              "684  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "\n",
              "        7         8         9      ...     49142     49143     49144  \\\n",
              "0    0.125490  0.356863  0.011765  ...  0.305882  0.058824  0.109804   \n",
              "1    0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
              "2    0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
              "3    0.000000  0.000000  0.050980  ...  0.266667  0.000000  0.000000   \n",
              "4    0.047059  0.227451  0.047059  ...  0.400000  0.054902  0.133333   \n",
              "..        ...       ...       ...  ...       ...       ...       ...   \n",
              "680  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
              "681  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
              "682  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
              "683  0.223529  0.337255  0.133333  ...  0.349020  0.321569  0.321569   \n",
              "684  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
              "\n",
              "        49145     49146     49147     49148     49149     49150     49151  \n",
              "0    0.305882  0.039216  0.070588  0.203922  0.000000  0.000000  0.000000  \n",
              "1    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "2    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "3    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "4    0.392157  0.011765  0.035294  0.101961  0.000000  0.000000  0.000000  \n",
              "..        ...       ...       ...       ...       ...       ...       ...  \n",
              "680  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "681  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "682  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "683  0.352941  0.321569  0.325490  0.356863  0.054902  0.054902  0.058824  \n",
              "684  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "\n",
              "[685 rows x 49152 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.DataFrame(X_train_flat)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler_X = StandardScaler()\n",
        "X_train_scaled = scaler_X.fit_transform(X_train_flat)\n",
        "X_test_scaled = scaler_X.transform(X_test_flat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "yJZHoUPJ1sq6"
      },
      "outputs": [],
      "source": [
        "X_train = X_train_scaled\n",
        "X_test = X_test_scaled\n",
        "y_train = y_train_decode\n",
        "y_test = y_test_decode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyveMW5B21cA",
        "outputId": "d16ca8ad-0355-470b-c6eb-bba79c8cc1a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "  France grn       1.00      1.00      1.00        27\n",
            "        Fuji       0.77      0.89      0.83        54\n",
            "    USA Envy       0.85      0.76      0.80        59\n",
            "    USA Koru       0.70      0.66      0.68        32\n",
            "\n",
            "    accuracy                           0.82       172\n",
            "   macro avg       0.83      0.83      0.83       172\n",
            "weighted avg       0.82      0.82      0.82       172\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#linear benchmark model\n",
        "model = SVC(kernel='linear')\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Q73SiaPs3AIZ"
      },
      "outputs": [],
      "source": [
        "#Fine tune linear SVM model\n",
        "\n",
        "parameters = {'C': [0.01,0.1, 1, 10, 100, 1000]}\n",
        "grid_search = GridSearchCV(SVC(kernel='linear'), parameters, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "best_params = grid_search.best_params_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.01"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_params['C']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_SkyZXQ5KKp",
        "outputId": "38998525-c48d-4f41-8715-93699e519913"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "  France grn       1.00      1.00      1.00        27\n",
            "        Fuji       0.77      0.89      0.83        54\n",
            "    USA Envy       0.85      0.76      0.80        59\n",
            "    USA Koru       0.70      0.66      0.68        32\n",
            "\n",
            "    accuracy                           0.82       172\n",
            "   macro avg       0.83      0.83      0.83       172\n",
            "weighted avg       0.82      0.82      0.82       172\n",
            "\n"
          ]
        }
      ],
      "source": [
        "optimal_model = SVC(kernel='linear', C=best_params['C'])\n",
        "optimal_model.fit(X_train, y_train)\n",
        "y_pred = optimal_model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7B3vJ2I5qBv",
        "outputId": "ebbdc17b-3825-4cdb-c273-55420b6f1a88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "  France grn       0.00      0.00      0.00        27\n",
            "        Fuji       0.00      0.00      0.00        54\n",
            "    USA Envy       0.34      1.00      0.51        59\n",
            "    USA Koru       0.00      0.00      0.00        32\n",
            "\n",
            "    accuracy                           0.34       172\n",
            "   macro avg       0.09      0.25      0.13       172\n",
            "weighted avg       0.12      0.34      0.18       172\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "#rbf\n",
        "model = SVC(kernel='rbf', C = 0.01)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgCVDnd-5vNR",
        "outputId": "720ddfe8-4804-43d0-ab91-11734670532b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
          ]
        }
      ],
      "source": [
        "#Fine tuning rbf kernal model\n",
        "parameters= {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],\n",
        "    'gamma': [1, 0.1, 0.01, 0.001],\n",
        "}\n",
        "model = SVC(kernel='rbf')\n",
        "\n",
        "# Setup GridSearchCV\n",
        "grid_search = GridSearchCV(model, parameters, cv=5, scoring='accuracy', verbose=1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "y_pred = grid_search.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=0.01, gamma=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=0.01, gamma=1)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "SVC(C=0.01, gamma=1)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grid_search.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "  France grn       0.00      0.00      0.00        27\n",
            "        Fuji       0.00      0.00      0.00        54\n",
            "    USA Envy       0.34      1.00      0.51        59\n",
            "    USA Koru       0.00      0.00      0.00        32\n",
            "\n",
            "    accuracy                           0.34       172\n",
            "   macro avg       0.09      0.25      0.13       172\n",
            "weighted avg       0.12      0.34      0.18       172\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hf2ygcUS6K5L",
        "outputId": "d04469dd-0080-4a5a-9ce2-961696640cd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
          ]
        }
      ],
      "source": [
        "parameters = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],             # Regularization parameter\n",
        "    'degree': [2, 3, 4, 5],              # Degree of the polynomial kernel   # Kernel coefficient\n",
        "}\n",
        "\n",
        "model = SVC(kernel='poly')\n",
        "\n",
        "# Setup GridSearchCV\n",
        "grid_search = GridSearchCV(model, parameters, cv=5, scoring='accuracy', verbose=1)\n",
        "\n",
        "# Perform grid search\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_svm = grid_search.best_estimator_\n",
        "y_pred = best_svm.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "  France grn       1.00      0.96      0.98        27\n",
            "        Fuji       0.65      0.93      0.76        54\n",
            "    USA Envy       0.88      0.59      0.71        59\n",
            "    USA Koru       0.72      0.66      0.69        32\n",
            "\n",
            "    accuracy                           0.77       172\n",
            "   macro avg       0.81      0.78      0.79       172\n",
            "weighted avg       0.80      0.77      0.76       172\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, y_pred))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
